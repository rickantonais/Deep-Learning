{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "\n",
    "#first we load the data we've uploaded before\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "Y = pickle.load(open(\"Y.pickle\",\"rb\"))\n",
    "\n",
    "#normalize our features\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24946, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we build our model\n",
    "model = Sequential()\n",
    "\n",
    "#1st layer\n",
    "model.add(Conv2D(64,(3,3), input_shape=X.shape[1:])) #we don't need the number of training example, only the shape of our input\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#2nd layer\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#3rd layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#compile our model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/3\n",
      "22451/22451 [==============================] - 633s 28ms/step - loss: 0.6599 - acc: 0.6055 - val_loss: 0.6430 - val_acc: 0.6421\n",
      "Epoch 2/3\n",
      "22451/22451 [==============================] - 601s 27ms/step - loss: 0.5771 - acc: 0.7025 - val_loss: 0.5816 - val_acc: 0.7066\n",
      "Epoch 3/3\n",
      "22451/22451 [==============================] - 598s 27ms/step - loss: 0.5277 - acc: 0.7379 - val_loss: 0.5354 - val_acc: 0.7331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c1cd201f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, batch_size=32, epochs=3, validation_split=0.1) #10% is chosen as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a new model with more filters for each layers\n",
    "model_bis = Sequential()\n",
    "\n",
    "model_bis.add(Conv2D(256,(3,3), input_shape=X.shape[1:]))\n",
    "model_bis.add(Activation(\"relu\"))\n",
    "model_bis.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_bis.add(Conv2D(256,(3,3)))\n",
    "model_bis.add(Activation(\"relu\"))\n",
    "model_bis.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model_bis.add(Flatten())\n",
    "model_bis.add(Dense(64))\n",
    "model_bis.add(Activation(\"relu\"))\n",
    "\n",
    "model_bis.add(Dense(1))\n",
    "model_bis.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model_bis.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/3\n",
      "22451/22451 [==============================] - 768s 34ms/step - loss: 0.6631 - acc: 0.5938 - val_loss: 0.6357 - val_acc: 0.6337\n",
      "Epoch 2/3\n",
      "22451/22451 [==============================] - 750s 33ms/step - loss: 0.6040 - acc: 0.6713 - val_loss: 0.5669 - val_acc: 0.7138\n",
      "Epoch 3/3\n",
      "22451/22451 [==============================] - 725s 32ms/step - loss: 0.5261 - acc: 0.7385 - val_loss: 0.5276 - val_acc: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c1cf8989e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bis.fit(X,Y,batch_size=32,epochs=3,validation_split=0.1) #10% is chosen as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
